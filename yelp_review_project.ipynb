{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews_processed = pd.read_csv(\"/Users/brandonwu/Downloads/yelp_review_data_processed.csv\")\n",
    "yelp_reviews_processed = yelp_reviews_processed.drop([\"review_id\", \"user_id\", \"business_id\", \"useful\", \"funny\", \"cool\", \"text\", \"date\"], axis=1)\n",
    "yelp_reviews_processed = yelp_reviews_processed.dropna(subset=[\"processed_text\"])\n",
    "yelp_reviews_processed[\"processed_text\"] = yelp_reviews_processed[\"processed_text\"].astype(\"string\")\n",
    "yelp_reviews_processed = yelp_reviews_processed.head(500000)\n",
    "\n",
    "tokenized_reviews = yelp_reviews_processed[\"processed_text\"].str.split().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences=tokenized_reviews, vector_size=300, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, model, vector_size=300):\n",
    "    review_vector = np.zeros(vector_size)\n",
    "    valid_words = 0\n",
    "    for word in tokens_list:\n",
    "        if word in model.wv:\n",
    "            review_vector += model.wv[word]\n",
    "            valid_words += 1\n",
    "    if valid_words > 0:\n",
    "        review_vector /= valid_words\n",
    "    return review_vector\n",
    "\n",
    "\n",
    "X = np.array([get_average_word2vec(review, word2vec_model) for review in tokenized_reviews])\n",
    "y = yelp_reviews_processed[\"stars\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD2VEC RESULTS FOR LOGISTIC REGRESSION\n",
      "Accuracy: 0.6265975\n",
      "Log Loss: 0.8788751885385395\n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75     13146\n",
      "           2       0.38      0.51      0.44      7816\n",
      "           3       0.38      0.48      0.43     10565\n",
      "           4       0.47      0.53      0.50     22638\n",
      "           5       0.84      0.70      0.76     45835\n",
      "\n",
      "    accuracy                           0.63    100000\n",
      "   macro avg       0.57      0.59      0.57    100000\n",
      "weighted avg       0.66      0.63      0.64    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)  \n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score = cross_val_score(lr_model, X_train_scaled, y_train, cv=10, scoring=\"accuracy\")\n",
    "log_loss_score = cross_val_score(lr_model, X_train_scaled, y_train, cv=10, scoring=\"neg_log_loss\")\n",
    "\n",
    "print(\"WORD2VEC RESULTS FOR LOGISTIC REGRESSION\")\n",
    "print(f\"Accuracy: {accuracy_score.mean()}\")\n",
    "print(f\"Log Loss: {-log_loss_score.mean()}\")\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD2VEC RESULTS FOR LOGISTIC REGRESSION\n",
      "Accuracy: 0.6664549999999999\n",
      "Log Loss: 0.8014429669602819\n",
      "\n",
      "CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.83      0.76     13146\n",
      "           2       0.45      0.28      0.35      7816\n",
      "           3       0.46      0.35      0.40     10565\n",
      "           4       0.52      0.44      0.48     22638\n",
      "           5       0.76      0.87      0.81     45835\n",
      "\n",
      "    accuracy                           0.67    100000\n",
      "   macro avg       0.58      0.55      0.56    100000\n",
      "weighted avg       0.64      0.67      0.65    100000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "accuracy_score = cross_val_score(lr_model, X_train_scaled, y_train, cv=10, scoring=\"accuracy\")\n",
    "log_loss_score = cross_val_score(lr_model, X_train_scaled, y_train, cv=10, scoring=\"neg_log_loss\")\n",
    "\n",
    "print(\"WORD2VEC RESULTS FOR LOGISTIC REGRESSION\")\n",
    "print(f\"Accuracy: {accuracy_score.mean()}\")\n",
    "print(f\"Log Loss: {-log_loss_score.mean()}\")\n",
    "print()\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD2VEC RESULTS FOR XGBOOST\n",
      "R-squared: [0.71518099 0.71717501 0.72027522 0.71569467 0.71950984 0.71466029\n",
      " 0.71964645 0.71900409 0.71800125 0.71402591]\n",
      "MSE: [-0.57146984 -0.56951195 -0.56250751 -0.56867981 -0.56759965 -0.56849658\n",
      " -0.56479174 -0.56411308 -0.57128447 -0.57084197]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR-squared: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "xg_model = XGBRegressor(n_estimators=400, learning_rate=0.05, max_depth=7, subsample=0.6, min_child_weight=1, random_state=42)\n",
    "xg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "r2_score = cross_val_score(xg_model, X_train_scaled, y_train, cv=10, scoring=\"r2\")\n",
    "mse_score = cross_val_score(xg_model, X_train_scaled, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(\"WORD2VEC RESULTS FOR XGBOOST\")\n",
    "print(f\"R-squared: {r2_score}\")\n",
    "print(f\"MSE: {mse_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
